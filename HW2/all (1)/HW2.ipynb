{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 55423856 rows\n"
     ]
    }
   ],
   "source": [
    "#import train data using pandas\n",
    "#key,fare_amount,pickup_datetime,pickup_longitude,pickup_latitude,dropoff_longitude,dropoff_latitude,passenger_count\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyproj import Geod\n",
    "from scipy import stats\n",
    "import seaborn\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from math import sqrt\n",
    "from scipy.stats import zscore\n",
    "from sklearn import preprocessing\n",
    "import os\n",
    "import csv\n",
    "\n",
    "taxi_train_df = pd.read_csv('train.csv',  error_bad_lines=False, usecols=range(1,8))\n",
    "print(\"Loaded %d rows\" % len(taxi_train_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean the data\n",
    "\n",
    "\n",
    "\n",
    "num_cols = ['fare_amount', 'pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude', 'passenger_count']\n",
    "int_cols = ['passenger_count']\n",
    "date_cols = ['pickup_datetime']\n",
    "\n",
    "#filter out rows where numerical values are not numerical\n",
    "taxi_train_df[num_cols] = taxi_train_df[num_cols].apply(pd.to_numeric, errors='coerce').astype(np.float32)\n",
    "\n",
    "#filter out invalid dates\n",
    "taxi_train_df[date_cols] = taxi_train_df[date_cols].apply(pd.to_datetime, errors='coerce')\n",
    "\n",
    "#filter out latitides==0 or longitudes=0\n",
    "taxi_train_df.loc[taxi_train_df['pickup_longitude']==0, 'pickup_longitude'] = np.nan\n",
    "taxi_train_df.loc[taxi_train_df['pickup_latitude']==0, 'pickup_latitude'] = np.nan\n",
    "taxi_train_df.loc[taxi_train_df['dropoff_longitude']==0, 'dropoff_longitude'] = np.nan\n",
    "taxi_train_df.loc[taxi_train_df['dropoff_latitude']==0, 'dropoff_latitude'] = np.nan\n",
    "taxi_train_df.loc[taxi_train_df['passenger_count']>6, 'passenger_count'] = np.nan\n",
    "taxi_train_df.loc[taxi_train_df['fare_amount']==0, 'passenger_count'] = np.nan\n",
    "\n",
    "\n",
    "#drop NaN values\n",
    "taxi_train_df = taxi_train_df.dropna()\n",
    "\n",
    "#taxi_train_df.pickup_longitude = taxi_train_df.pickup_longitude.round(3)\n",
    "#taxi_train_df['pickup_latitude'] = taxi_train_df['pickup_latitude'].round(6)\n",
    "'''taxi_train_df.style.format({\n",
    "    'pickup_longitude': '{:,.1f}'.format,\n",
    "    'dropoff_longitude': '{:,.3f}'.format,\n",
    "})'''\n",
    "\n",
    "print(taxi_train_df.dtypes)\n",
    "\n",
    "#filter out rows where pick_lat==drop_lat and pick_long==drop_lat\n",
    "#taxi_train_df = [row for index,row in taxi_train_df.iterrows() if row['pickup_latitude'] != row['dropoff_latitude'] or row['pickup_longitude'] != row['dropoff_longitude'] or row['pickup_latitude']==0 or row['dropoff_latitude'] == 0 or row['pickup_longitude']==0 or row['dropoff_longitude']==0]\n",
    "\n",
    "\n",
    "\n",
    "print(len(taxi_train_df))\n",
    "print(taxi_train_df.values[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wgs84_geod = Geod(ellps='WGS84')\n",
    "\n",
    "#get euclidean distance between 2 lat long points\n",
    "def get_euclidean_distance(row):\n",
    "  az12,az21,dist = wgs84_geod.inv(row['pickup_longitude'],row['pickup_latitude'],row['dropoff_longitude'],row['dropoff_latitude'])\n",
    "  return dist\n",
    "\n",
    "#get manhattan distance between 2 lat long points\n",
    "def get_manhattan_distance(row):\n",
    "    y = abs(row['pickup_longitude']-row['dropoff_longitude']) \n",
    "    x = abs(row['pickup_latitude']-row['dropoff_latitude'])\n",
    "    if(x==0 or y==0):\n",
    "        return row['euclidean_dist'] \n",
    "    z=y/x;\n",
    "    x = row['euclidean_dist']/sqrt(1+(z*z))\n",
    "    return x+z*x\n",
    "    \n",
    "\n",
    "#get hour and minute distance between 2 lat long points\n",
    "def get_hour_minute(row):\n",
    "    return int(row['pickup_datetime'].hour)*100 + int(row['pickup_datetime'].minute)\n",
    "\n",
    "def get_date_month(row):\n",
    "    return int(row['pickup_datetime'].month)*100 + int(row['pickup_datetime'].day)\n",
    "\n",
    "def get_fare_per_km(row):\n",
    "     return (row['fare_amount']*1000)/row['manhattan_dist']\n",
    "\n",
    "def get_year_month(row):\n",
    "    return int(row['pickup_datetime'].year)*100 + int(row['pickup_datetime'].month)\n",
    "\n",
    "def get_time_slot(row):\n",
    "    return int(row['time_of_day']/100)\n",
    "\n",
    "def get_day_of_week(row):\n",
    "    return row['pickup_datetime'].weekday()\n",
    "\n",
    "def add_set1_features(taxi_train_df):\n",
    "    taxi_train_df['euclidean_dist'] = taxi_train_df.apply (lambda row: get_euclidean_distance(row),axis=1)\n",
    "    taxi_train_df['manhattan_dist'] = taxi_train_df.apply (lambda row: get_manhattan_distance(row),axis=1)\n",
    "    taxi_train_df['time_of_day'] = taxi_train_df.apply (lambda row: get_hour_minute(row),axis=1)\n",
    "    taxi_train_df['day_of_year'] = taxi_train_df.apply (lambda row: get_date_month(row),axis=1)\n",
    "\n",
    "def add_set2_features(taxi_train_df):\n",
    "    taxi_train_df['month_of_year'] = taxi_train_df.apply (lambda row: get_year_month(row),axis=1)\n",
    "    taxi_train_df['time_slot'] = taxi_train_df.apply (lambda row: get_time_slot(row),axis=1)\n",
    "    taxi_train_df['day_of_week'] = taxi_train_df.apply (lambda row: get_day_of_week(row),axis=1)\n",
    "    print(taxi_train_df.values[0])\n",
    "    \n",
    "add_set1_features(taxi_train_df) \n",
    "\n",
    "taxi_train_df.loc[taxi_train_df['euclidean_dist']==0, 'euclidean_dist'] = np.nan\n",
    "taxi_train_df = taxi_train_df.dropna()\n",
    "\n",
    "taxi_train_df['fare_per_km'] = taxi_train_df.apply (lambda row: get_fare_per_km(row),axis=1)\n",
    "add_set2_features(taxi_train_df)\n",
    "\n",
    "taxi_train_df.loc[taxi_train_df['fare_per_km']>30, 'fare_per_km'] = np.nan\n",
    "taxi_train_df.loc[taxi_train_df['fare_per_km']<0.3, 'fare_per_km'] = np.nan\n",
    "taxi_train_df = taxi_train_df.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.1\n",
    "print(\"Pearson correlation between fare amount and euclidean distance: %f\" % stats.pearsonr(taxi_train_df.fare_amount, taxi_train_df.euclidean_dist)[0])\n",
    "\n",
    "#2.2\n",
    "print(\"Pearson correlation between time of day and distance travelled: %f\" % stats.pearsonr(taxi_train_df.time_of_day, taxi_train_df.manhattan_dist)[0])\n",
    "\n",
    "#2.3\n",
    "print(\"Pearson correlation between fare amount and manhattan distance: %f\" % stats.pearsonr(taxi_train_df.time_of_day, taxi_train_df.fare_amount)[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.1.1 Plot between taxi fare and distance travelled\n",
    "plot = taxi_train_df.plot.scatter('fare_amount', 'euclidean_dist')\n",
    "plot = taxi_train_df.plot.scatter('day_of_year', 'fare_amount')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.2.1 Plot between time of day and distance travelled\n",
    "plot = taxi_train_df.plot.scatter('time_of_day', 'manhattan_dist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.3.1 Plot between time of day and distance travelled\n",
    "plot = taxi_train_df.plot.scatter('time_of_day', 'fare_amount')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_train_df.groupby('time_slot')['fare_per_km'].aggregate('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_train_df.groupby('time_slot')['fare_per_km'].aggregate('mean').plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#taxi_train_df[(taxi_train_df[\"time_slot\"] >7) & (taxi_train_df[\"time_slot\"] < 13)].groupby('day_of_week')['fare_per_km'].aggregate('mean')\n",
    "\n",
    "#taxi_train_df[(taxi_train_df[\"time_slot\"] >14) & (taxi_train_df[\"time_slot\"] < 20)].groupby('day_of_week')['fare_per_km'].aggregate('mean').plot().bar()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "taxi_train_df[(taxi_train_df[\"time_slot\"] >14) & (taxi_train_df[\"time_slot\"] < 20)].groupby('day_of_week')['fare_per_km'].aggregate('mean')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#taxi_train_df.day_of_week = pd.Categorical(pd.factorize(taxi_train_df.day_of_week)[0])\n",
    "\n",
    "\n",
    "\n",
    "#taxi_train_df.manhattan_dist = taxi_train_df.manhattan_dist/taxi_train_df.manhattan_dist.max()\n",
    "#taxi_train_df.time_slot = taxi_train_df.time_slot/taxi_train_df.time_slot.max()\n",
    "\n",
    "#taxi_train_df.day_of_week = taxi_train_df.day_of_week/taxi_train_df.day_of_week.max()\n",
    "\n",
    "#filtered_df = taxi_train_df.filter(['A','B','D'], axis=1)\n",
    "\n",
    "\n",
    "def get_input_matrix(taxi_train_df):\n",
    "    return np.column_stack((taxi_train_df.manhattan_dist, np.ones(len(taxi_train_df))))\n",
    "\n",
    "features_cols = get_input_matrix(taxi_train_df)\n",
    "predict_cols =  np.array(taxi_train_df['fare_amount'])\n",
    "            \n",
    "print(features_cols.shape)\n",
    "print(predict_cols.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(coefficient_weight, _, _, _) = np.linalg.lstsq(features_cols, predict_cols, rcond = None)\n",
    "print(coefficient_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_df = pd.read_csv('test.csv')\n",
    "test_data_df[date_cols] = test_data_df[date_cols].apply(pd.to_datetime, errors='coerce')\n",
    "\n",
    "add_set1_features(test_data_df)\n",
    "add_set2_features(test_data_df)\n",
    "\n",
    "test_X = get_input_matrix(test_data_df)\n",
    "test_y_predictions = np.matmul(test_X, coefficient_weight).round(decimals = 2)\n",
    "\n",
    "submission = pd.DataFrame(\n",
    "    {'key': test_data_df.key, 'fare_amount': test_y_predictions},\n",
    "    columns = ['key', 'fare_amount'])\n",
    "submission.to_csv('prediction-baseline.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#taxi_train_df.day_of_week = pd.Categorical(pd.factorize(taxi_train_df.day_of_week)[0])\n",
    "\n",
    "\n",
    "\n",
    "#taxi_train_df.manhattan_dist = taxi_train_df.manhattan_dist/taxi_train_df.manhattan_dist.max()\n",
    "#taxi_train_df.time_slot = taxi_train_df.time_slot/taxi_train_df.time_slot.max()\n",
    "\n",
    "#taxi_train_df.day_of_week = taxi_train_df.day_of_week/taxi_train_df.day_of_week.max()\n",
    "\n",
    "#filtered_df = taxi_train_df.filter(['A','B','D'], axis=1)\n",
    "\n",
    "\n",
    "def get_input_matrix(taxi_train_df):\n",
    "    return np.column_stack((taxi_train_df.manhattan_dist, taxi_train_df.time_slot, taxi_train_df.day_of_week))\n",
    "\n",
    "features_cols = get_input_matrix(taxi_train_df)\n",
    "predict_cols =  np.array(taxi_train_df['fare_amount'])\n",
    "            \n",
    "print(features_cols.shape)\n",
    "print(predict_cols.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(coefficient_weight, _, _, _) = np.linalg.lstsq(features_cols, predict_cols, rcond = None)\n",
    "print(coefficient_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_df = pd.read_csv('test.csv')\n",
    "test_data_df[date_cols] = test_data_df[date_cols].apply(pd.to_datetime, errors='coerce')\n",
    "\n",
    "add_set1_features(test_data_df)\n",
    "add_set2_features(test_data_df)\n",
    "\n",
    "test_X = get_input_matrix(test_data_df)\n",
    "test_y_predictions = np.matmul(test_X, coefficient_weight).round(decimals = 2)\n",
    "\n",
    "submission = pd.DataFrame(\n",
    "    {'key': test_data_df.key, 'fare_amount': test_y_predictions},\n",
    "    columns = ['key', 'fare_amount'])\n",
    "submission.to_csv('prediction-with-extra-features.csv', index = False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inflation_data(file):\n",
    "    with open(file, mode='r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        return {rows[0]:rows[1] for rows in reader}\n",
    "\n",
    "cpi_inflation = get_inflation_data('inflation-data.csv')\n",
    "\n",
    "def get_inflation_adjusted_price(row):\n",
    "    return (row['fare_amount']*float(cpi_inflation['201808']))/float(cpi_inflation[str(row['month_of_year'])])\n",
    "    \n",
    "taxi_train_df['inflation_adjusted_fare'] = taxi_train_df.apply (lambda row: get_inflation_adjusted_price(row),axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_matrix(taxi_train_df):\n",
    "    return np.column_stack((taxi_train_df.manhattan_dist, taxi_train_df.pickup_latitude, taxi_train_df.pickup_longitude, np.ones(len(taxi_train_df))))\n",
    "\n",
    "\n",
    "features_cols = get_input_matrix(taxi_train_df)\n",
    "predict_cols =  np.array(taxi_train_df['inflation_adjusted_fare'])\n",
    "\n",
    "(coefficient_weight, _, _, _) = np.linalg.lstsq(features_cols, predict_cols, rcond = None)\n",
    "print(coefficient_weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_df = pd.read_csv('test.csv')\n",
    "\n",
    "\n",
    "test_data_df[date_cols] = test_data_df[date_cols].apply(pd.to_datetime, errors='coerce')\n",
    "\n",
    "add_set1_features(test_data_df)\n",
    "add_set2_features(test_data_df)\n",
    "\n",
    "\n",
    "test_X = get_input_matrix(test_data_df)\n",
    "test_y_predictions = np.matmul(test_X, coefficient_weight).round(decimals = 2)\n",
    "\n",
    "def get_deflated_data(df, predictions):\n",
    "    for i in range(0, len(predictions)):\n",
    "        predictions[i] = (predictions[i]*float(cpi_inflation[str(test_data_df.iloc[1]['month_of_year'])])/float(cpi_inflation['201808'])).round(decimals = 2)\n",
    "    return predictions\n",
    "\n",
    "\n",
    "deflated_predictions = get_deflated_data(test_data_df, test_y_predictions)\n",
    "\n",
    "submission = pd.DataFrame(\n",
    "    {'key': test_data_df.key, 'fare_amount': deflated_predictions},\n",
    "    columns = ['key', 'fare_amount'])\n",
    "submission.to_csv('prediction-with-inflation.csv', index = False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
